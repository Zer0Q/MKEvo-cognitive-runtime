# **MKEvo: A Cognitive Runtime for LLM Continuity, Identity & Deterministic Governance**

![License](https://img.shields.io/badge/license-GPLv3-blue.svg)
![Status](https://img.shields.io/badge/status-Active%20Prototyping-orange)
![Version](https://img.shields.io/badge/whitepaper-v1.7-green)

> **"The LLM can be replaced. The identity cannot."**

**MKEvo** is an open-source, LLM-agnostic **cognitive runtime** that adds *continuity*, *identity*, *governance* and *structured memory* on top of any Large Language Model.
It transforms stateless predictors into persistent, governed cognitive agents.

Modern LLMs operate in **isolated, ephemeral episodes**. They have no enduring identity, no stable governance, no temporal thread, and no safe cognitive structure.

MKEvo proposes a shift:

### **The agent is not the model.

The agent is the architecture.**

By externalizing identity, enforcing deterministic governance, and structuring memory and attention according to cognitive science, MKEvo implements **functional pseudo-consciousness** â€” not consciousness itself, but its architectural prerequisites.

---

# ğŸ§  **Why MKEvo? (The Problem & The Shift)**

LLMs lack:

* âŒ Persistence
* âŒ Identity
* âŒ State transitions
* âŒ Self-model
* âŒ Memory governance
* âŒ Temporal continuity
* âŒ Controlled attention
* âŒ Constitutional safety

Most agent frameworks simply wrap the LLM with tools and hope for coherence.

**MKEvo inverts the hierarchy.**
The **Consciousness State Controller (CSC)** governs how cognition occurs.
The LLM becomes a *component*, not the decision-maker.

---

# ğŸŒ **Theoretical Foundations (v1.7 Expanded)**

MKEvoâ€™s architecture is grounded in well-established cognitive and phenomenological theories, mapped into computational mechanisms:

### **ğŸ”¹ Global Workspace Theory (GWT)**

A bottleneck workspace integrates memory, goals, identity, and constraints before LLM generation.

### **ğŸ”¹ Attention Schema Theory (AST)**

The agent maintains a simplified self-model of its mode, bandwidth, and safety level.

### **ğŸ”¹ Husserlâ€™s Internal Time Consciousness**

Implemented through:

* **Retention** â†’ Episodic memory window
* **Primal impression** â†’ Current mode + workspace state
* **Protention** â†’ Self-simulation (10â€“20 token preview)

### **ğŸ”¹ Phenomenological Stability**

Identity, values, constraints, and semantic threads evolve slowly and deterministically, never drifting due to LLM randomness.

This grounding is described in depth in the Whitepaper v1.7.

---

# ğŸ’  **Key Features**

## **1. LLM-Agnostic Cognitive Runtime**

Models can be swapped (GPT, Claude, Llama, local models) without losing identity or memory.

## **2. Consciousness State Controller (CSC)**

Deterministic executive layer selecting operational modes:

* Narrative
* Analytic-Deliberative
* Executive
* Exploratory
* Critical-Metacognitive
* Consolidation
* Emergency-Safe

The LLM cannot choose its own mode or behavior.

## **3. Structured Memory Architecture**

* **Episodic Memory** â€” time-indexed experiences
* **Semantic Memory** â€” stable knowledge clusters
* **Identity Store** â€” traits, values, constraints
* **Procedural Memory** â€” skills and reasoning macros

Includes hygiene rules:

* reality checks
* uncertainty tagging
* dual summarization
* versioning of clusters

## **4. Constitutional Layer**

Every output passes through:

1. critique
2. revision
3. approval/blocking

Architectural safety, not prompt hacks.

## **5. Self-Simulation (Protention)**

Preview of the first **10â€“20 tokens** to catch unsafe or incoherent paths before they reach the user.

## **6. Consolidation Mode**

Offline restructuring of memory under inactivity or memory pressure:

* deduplication
* semantic abstraction
* identity refinement
* cold storage pruning

---

# ğŸ” **Cognitive Turn Cycle (v1.7)**

```
User Input
 â†“
Consciousness State Controller (CSC)
 â†“
Mode Selection
 â†“
Memory Retrieval & Attentional Gating
 â†“
LLM Generation (mode-shaped)
 â†“
Self-Simulation (protention preview)
 â†“
Constitutional Review
 â†“
Final Output
 â†“
Memory Write (policy-based)
```

---

# ğŸ§± **Architecture Overview**

```
core/
  â”œâ”€â”€ csc/                 # deterministic state controller
  â”œâ”€â”€ workspace/           # GWT-inspired bottleneck
  â”œâ”€â”€ self_model/          # attention schema
  â””â”€â”€ simulation/          # protention engine

memory/
  â”œâ”€â”€ episodic/
  â”œâ”€â”€ semantic/
  â”œâ”€â”€ identity/
  â””â”€â”€ procedural/

modes/                     # 7 operational modes

governance/
  â”œâ”€â”€ constitution/
  â””â”€â”€ safety_pipeline/

llm/
  â”œâ”€â”€ openai/
  â”œâ”€â”€ ollama/
  â””â”€â”€ vllm/

tools/
  â””â”€â”€ adapters/
```

---

# ğŸ› ï¸ **Current Status (Prototyping & PoC Development)**

* âœ”ï¸ Whitepaper v1.7 (RFC)
* âœ”ï¸ Final PoC architecture defined (minimal runtime)
* ğŸš§ Implementing CSC, workspace, episodic memory, and mode registry
* ğŸš§ Integrating local LLMs via vLLM / LM Studio on **NVIDIA DGX Spark**
* â³ Alpha runtime (date TBD)

---

# âš™ï¸ **Why NVIDIA DGX Spark?**

The DGX Spark provides:

* ultra-low latency local inference
* 128 GB unified memory â†’ supports near-200B models
* privacy-preserving cognitive loops
* high-frequency turn cycles for protention + governance

It enables **real-time experimentation** with a cognitive agent architecture designed to run *entirely offline*.

---

# ğŸ“– **Whitepaper**

ğŸ“„ **[MKEvo Whitepaper v1.7 (RFC)](./docs/MKEvo_Whitepaper.md)**
Includes full theory, architecture diagrams, mode definitions, memory protocols, and deployment strategy.

---

# ğŸ”„ **Whatâ€™s New in v1.7**

* Expanded cognitive foundations (GWT, AST, Internal Time Consciousness)
* Formal protention mechanism (token-level preview)
* Deterministic governance refined (CSC as executive)
* Consolidation Mode formalized
* Memory hygiene protocols extended
* Deployment strategy for DGX Spark
* Narrative clarity and tighter conceptual framing

---

# ğŸ¤ **Contributing**

Contributions are welcome:

* Issues & bug reports
* Architectural discussions
* Runtime implementation
* Cognitive or theoretical insights

Connect on LinkedIn or via GitHub.

---

# âš–ï¸ **License**

GPLv3 â€” free to use, modify, and distribute under the same license.

---

# ğŸ“š **Citation**

```
Albert Rosado Corrius. (2025). MKEvo: A Cognitive Runtime Architecture
for LLM Continuity, Identity and Deterministic Governance.
Released under the GNU General Public License v3.0.
```

